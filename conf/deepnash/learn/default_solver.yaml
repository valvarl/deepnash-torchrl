defaults:
  - deployment_config: deployment/default_solver

adam_config:
  b1: 0.0
  b2: 0.999
  eps: 1e-8

nerd_config:
  beta: 2.0
  clip: 10000

rnad_config:
  game_name: "stratego"
  trajectory_max: 10
  state_representation: "info_set"  # or "observation"
  policy_network_layers: [256, 256]
  batch_size: 256
  learning_rate: 0.0005
  adam:
    b1: 0.0
    b2: 0.999
    eps: 1e-8
  clip_gradient: 10000
  target_network_avg: 0.001
  entropy_schedule_repeats: [200, 1]
  entropy_schedule_size: [100, 100]
  eta_reward_transform: 0.2
  nerd:
    beta: 2.0
    clip: 10000
  c_vtrace: 1.0
  seed: 42

deployment_config:
  mode: "parallel"  # or sequential (for single device only)
  sequential_actor_learner_ratio: 0.25
  sequential_step_duration: 300
  num_instances: 1
  instance_gpu_capacity: 2
  actor_gpu_count: 1
  learner_gpu_count: 1
  shared_replay_buffer: false

event_config:
  use_wandb: true
  log_mod: 10
  expl_mod: 20
  checkpoint_mod: 50
  intra_instance_sync_mod: 5
  inter_instance_sync_mod: 20
  actor_update_mod: 5
